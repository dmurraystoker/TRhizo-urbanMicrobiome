---
title: "TRhizo-urbanMicrobiome"
subtitle: "DADA2 Pipeline"
author: "David Murray-Stoker"
output:
  pdf_document:
    toc: true
    toc_depth: 4
    fig_caption: yes
    latex_engine: xelatex
always_allow_html: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
knitr::opts_chunk$set(results = "hold", fig.pos = "H", fig.align = "center", out.width = "92.5%")
options(knitr.graphics.error = FALSE)
kableExtra::usepackage_latex("float")
```

```{r Load Packages for R Markdown, include = FALSE}
library(kableExtra)
library(knitr)
```





\newpage
# Load Packages

\vspace{10pt}

```{r Load Packages & Data, include = FALSE}
## Load the tidyverse
library(tidyverse)

## Load DADA2
library(dada2)

## Load the workspace
load("data_analysis/2-DADA2_pipeline/DADA2_pipeline-full_workspace.Rdata")
```





\newpage
# Root DADA2

\vspace{10pt}

```{r Roots: Set File Path & Names, echo = TRUE}
## Directory for fastq files
root.fastq.path <- "urbanMicrobiome_sequences/root"

## Set forward and reverse reads
root.forward.reads <- sort(
  list.files(root.fastq.path, pattern = "_L001_R1_001.fastq", full.names = TRUE)
)
root.reverse.reads <- sort(
  list.files(root.fastq.path, pattern = "_L001_R2_001.fastq", full.names = TRUE)
)

## Extract sample names
root.sample.names <- sapply(strsplit(basename(root.forward.reads), "_"), `[`, 1)
```

\vspace{10pt}

```{r Roots: Prefiltering of Ambiguous Bases, echo = TRUE}
## Set directories for filtered ambiguous base sequences
# Root forward reads
root.forward.reads.filtered <- file.path(
  root.fastq.path,
  "filtered_N",
  basename(root.forward.reads)
)
# Root reverse reads
root.reverse.reads.filtered <- file.path(
  root.fastq.path,
  "filtered_N",
  basename(root.reverse.reads)
)

## Filter ambiguous bases
filterAndTrim(
  fwd = root.forward.reads,
  filt = root.forward.reads.filtered,
  rev = root.reverse.reads,
  filt.rev = root.reverse.reads.filtered,
  maxN = 0,
  multithread = TRUE
)
```


\newpage
## Read Quality Profiles

\vspace{10pt}

```{r Roots Quality Profiles: Forward Reads, echo = FALSE, fig.cap = "Quality profile plots for the forward reads. Forward reads have high quality scores (> 30) until approximately 240 bp, after which the sequence should be trimmed. The first 20 bp of the forward reads should also be trimmed (primer removal)."}
## Examine quality profile plots for the forward reads
plotQualityProfile(root.forward.reads.filtered[1:20])
```

\vspace{10pt}

```{r Roots Quality Profiles: Reverse Reads, echo = FALSE, fig.cap = "Quality profile plots for the reverse reads. Reverse reads have high quality scores (> 30) until approximately 230 bp, after which the sequence should be trimmed. The first 21 bp of the reverse reads should also be trimmed (primer removal)."}
## Examine quality profile plots for the reverse reads
plotQualityProfile(root.forward.reads.filtered[1:20])
```


\newpage
### Filter & Trim Reads

\vspace{10pt}

```{r Roots: Set Directory & Names for Filtered Reads, echo = TRUE}
## Set directories for filtered forward and reverse reads
root.filtered.forward.reads <- file.path(
  root.fastq.path, "filtered", paste0(root.sample.names, "_F_filt.fastq.gz")
)
root.filtered.reverse.reads <- file.path(
  root.fastq.path, "filtered", paste0(root.sample.names, "_R_filt.fastq.gz")
)

## Set names for filtered reads
names(root.filtered.forward.reads) <- root.sample.names
names(root.filtered.reverse.reads) <- root.sample.names
```

\vspace{10pt}

```{r Roots: Filter Reads, echo = TRUE}
## Filter reads using standard parameters for the DADA2 pipeline
root.read.filtering <- filterAndTrim(
  fwd = root.forward.reads,
  filt = root.filtered.forward.reads,
  rev = root.reverse.reads,
  filt.rev = root.filtered.reverse.reads,
  truncLen = c(240, 230),
  trimLeft = c(20, 21), # forward primer, reverse primer (forward read)
  trimRight = c(21, 20), # reverse primer, forward primer (reverse read)
  maxN = 0,
  maxEE = c(2, 2),
  truncQ = 2,
  rm.phix = TRUE,
  compress = TRUE,
  multithread = TRUE
)
```


\newpage
## Learn the Error Rates

\vspace{10pt}

```{r Roots: Learn Error Rates for Forward and Reverse Reads, echo = TRUE, results = "hide"}
## Learn error rate for forward reads
root.forward.error.rate <- learnErrors(root.filtered.forward.reads, multithread = TRUE)
# 113325960 total bases in 515118 reads from 9 samples will be used for learning the error rates

## Learn error rate for reverse reads
root.reverse.error.rate <- learnErrors(root.filtered.reverse.reads, multithread = TRUE)
# 107659662 total bases in 515118 reads from 9 samples will be used for learning the error rates
```

\vspace{10pt}

```{r Roots Plot Error Rates: Forward Reads, echo = FALSE, fig.cap = "Plots of forward read error rates for each possible transition. Points are observed rates for each consensus quality score. The black line shows the estimate error rates from the machine-learning algorithm, while the red line shows the error rates based on Q-scores. There is a good fit between black lines and observed points."}
plotErrors(root.forward.error.rate, nominalQ = TRUE)
```

\vspace{10pt}

```{r Roots Plot Error Rates: Reverse Reads, echo = FALSE, fig.cap = "Plots of reverse read error rates for each possible transition. Points are observed rates for each consensus quality score. The black line shows the estimate error rates from the machine-learning algorithm, while the red line shows the error rates based on Q-scores. There is a good fit between black lines and observed points."}
plotErrors(root.reverse.error.rate, nominalQ = TRUE)
```


\newpage
## Sample Inference with DADA2

\vspace{10pt}

```{r Roots Sample Inference: Forward Reads, echo = TRUE}
## Run the DADA algorithm on the forward reads with the learned error rate
root.forward.DADA <- dada(
  derep = root.filtered.forward.reads,
  err = root.forward.error.rate,
  multithread = TRUE
)

## Inspect the forward DADA object
root.forward.DADA[[1]]
# 1487 sequence variants were inferred from 38190 input unique sequences
```

\vspace{10pt}

```{r Roots Sample Inference: Reverse Reads, echo = TRUE}
## Run the DADA algorithm on the reverse reads with the learned error rate
root.reverse.DADA <- dada(
  derep = root.filtered.reverse.reads,
  err = root.reverse.error.rate,
  multithread = TRUE
)

## Inspect the reverse DADA object
root.reverse.DADA[[1]]
# 1192 sequence variants were inferred from 48516 input unique sequences
```


\newpage
## Merge Paired Reads

\vspace{10pt}

```{r Roots: Merge Paired Reads, echo = TRUE}
## Merge forward and reverse reads to obtain the full, denoised sequences
root.merged.sequences <- mergePairs(
  dadaF = root.forward.DADA,
  derepF = root.filtered.forward.reads,
  dadaR = root.reverse.DADA,
  derepR = root.filtered.reverse.reads,
  verbose = TRUE
)
```

\vspace{10pt}

## Construct Sequence Table

\vspace{10pt}

```{r Roots: Construct Sequence Table from Merged Paired Reads, echo = TRUE}
## Create an Amplicon Sequence Variant (ASV) table from merged paired reads
root.sequence.table <- makeSequenceTable(root.merged.sequences)
```

\vspace{10pt}

## Remove Chimeras

\vspace{10pt}

```{r Roots: Remove Chimeras from the ASV Table, echo = TRUE, results = "hide"}
## Identify chimeric sequences using standard DADA2 parameters
root.sequence.table.filtered.for.chimeras <- removeBimeraDenovo(
  unqs = root.sequence.table,
  method = "consensus",
  multithread = TRUE,
  verbose = TRUE
)

## Relative frequency of chimeras
sum(root.sequence.table.filtered.for.chimeras / sum(root.sequence.table))
# Chimeras account for approximately 1.09% of all sequences
```


\newpage
## Track Reads through the DADA2 Pipeline

\vspace{10pt}

```{r Roots: Track Reads, echo = TRUE}
## Function to get unique reads
get_N_uniques <- function(x) {
  sum(getUniques(x))
}

## Determine the number of reads at each step
root.read.tracking <- tibble(
  root.read.filtering,
  sapply(root.forward.DADA, get_N_uniques),
  sapply(root.reverse.DADA, get_N_uniques),
  sapply(root.merged.sequences, get_N_uniques),
  rowSums(root.sequence.table.filtered.for.chimeras)
)

## Set column names
colnames(root.read.tracking) <- c(
  "Filtered", "Forward_Denoised", "Reverse_Denoised",
  "Merged_Sequences", "ASVs_No_Chimeras"
)

## Set row names
rownames(root.read.tracking) <- root.sample.names
```

\vspace{10pt}

```{r Roots: Table of Tracked Sequences, echo = FALSE}
kable(
  root.read.tracking,
  booktabs = TRUE,
  digits = 3,
  caption = "Number of reads for each step through the bioinformatic pipeline for all root samples."
) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"))
```


\newpage
## Taxonomy Assignment

\vspace{10pt}

```{r Roots: Assign Taxonomy Using the RDP Classifier, echo = TRUE}
## Assign taxonomy using the RDP naive Bayesian classifier
root.ASV.RDP.taxonomy.assignment <- assignTaxonomy(
  seqs = root.sequence.table.filtered.for.chimeras,
  refFasta = "rdp_train_set_18.fa.gz",
  tryRC = TRUE,
  taxLevels = c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus"),
  multithread = TRUE
)
```




\newpage
# Soil DADA2

\vspace{10pt}

```{r Soil: Set File Path & Names, echo = TRUE}
## Directory for fastq files
soil.fastq.path <- "urbanMicrobiome_sequences/soil"

## Set forward and reverse reads
soil.forward.reads <- sort(
  list.files(soil.fastq.path, pattern = "_L001_R1_001.fastq", full.names = TRUE)
)
soil.reverse.reads <- sort(
  list.files(soil.fastq.path, pattern = "_L001_R2_001.fastq", full.names = TRUE)
)

## Extract sample names
soil.sample.names <- sapply(strsplit(basename(soil.forward.reads), "_"), `[`, 1)
```

\vspace{10pt}

```{r Soil: Prefiltering of Ambiguous Bases, echo = TRUE}
## Set directories for filtered ambiguous base sequences
# Root forward reads
soil.forward.reads.filtered <- file.path(
  soil.fastq.path,
  "filtered_N",
  basename(soil.forward.reads)
)
# Root reverse reads
soil.reverse.reads.filtered <- file.path(
  soil.fastq.path,
  "filtered_N",
  basename(soil.reverse.reads)
)

## Filter ambiguous bases
filterAndTrim(
  fwd = soil.forward.reads,
  filt = soil.forward.reads.filtered,
  rev = soil.reverse.reads,
  filt.rev = soil.reverse.reads.filtered,
  maxN = 0,
  multithread = TRUE
)
```


\newpage
## Read Quality Profiles

```{r Roots Quality Profiles: Forward Reads, echo = FALSE, fig.cap = "Quality profile plots for the forward reads. Forward reads have high quality scores (> 30) until approximately 275 bp, after which the sequence should be trimmed. The first 20 bp of the forward reads should also be trimmed (primer removal)."}
## Examine quality profile plots for the forward reads
plotQualityProfile(soil.forward.reads.filtered[1:20])
```

\vspace{10pt}

```{r Roots Quality Profiles: Reverse Reads, echo = FALSE, fig.cap = "Quality profile plots for the reverse reads. Reverse reads have high quality scores (> 30) until approximately 250 bp, after which the sequence should be trimmed. The first 21 bp of the reverse reads should also be trimmed (primer removal)."}
## Examine quality profile plots for the reverse reads
plotQualityProfile(soil.forward.reads.filtered[1:20])
```


\newpage
### Filter & Trim Reads

\vspace{10pt}

```{r Soil: Set Directory & Names for Filtered Reads, echo = TRUE}
## Set directories for filtered forward and reverse reads
soil.filtered.forward.reads <- file.path(
  soil.fastq.path, "filtered", paste0(soil.sample.names, "_F_filt.fastq.gz")
)
soil.filtered.reverse.reads <- file.path(
  soil.fastq.path, "filtered", paste0(soil.sample.names, "_R_filt.fastq.gz")
)

## Set names for filtered reads
names(soil.filtered.forward.reads) <- soil.sample.names
names(soil.filtered.reverse.reads) <- soil.sample.names
```

\vspace{10pt}

```{r Soil: Filter Reads, echo = TRUE}
## Filter reads using standard parameters for the DADA2 pipeline
soil.read.filtering <- filterAndTrim(
  fwd = soil.forward.reads,
  filt = soil.filtered.forward.reads,
  rev = soil.reverse.reads,
  filt.rev = soil.filtered.reverse.reads,
  truncLen = c(275, 250),
  trimLeft = c(20, 21), # forward primer, reverse primer (forward read)
  trimRight = c(21, 20), # reverse primer, forward primer (reverse read)
  maxN = 0,
  maxEE = c(2, 2),
  truncQ = 2,
  rm.phix = TRUE,
  compress = TRUE,
  multithread = TRUE
)
```


\newpage
## Learn the Error Rates

\vspace{10pt}

```{r Soil: Learn Error Rates for Forward and Reverse Reads, echo = TRUE, results = "hide"}
## Learn error rate for forward reads
soil.forward.error.rate <- learnErrors(soil.filtered.forward.reads, multithread = TRUE)
# 112921140 total bases in 442828 reads from 7 samples will be used for learning the error rates

## Learn error rate for reverse reads
soil.reverse.error.rate <- learnErrors(soil.filtered.reverse.reads, multithread = TRUE)
# 101407612 total bases in 442828 reads from 7 samples will be used for learning the error rates
```

\vspace{10pt}

```{r Roots Plot Error Rates: Forward Reads, echo = FALSE, fig.cap = "Plots of forward read error rates for each possible transition. Points are observed rates for each consensus quality score. The black line shows the estimate error rates from the machine-learning algorithm, while the red line shows the error rates based on Q-scores. There is a good fit between black lines and observed points."}
plotErrors(soil.forward.error.rate, nominalQ = TRUE)
```

\vspace{10pt}

```{r Roots Plot Error Rates: Reverse Reads, echo = FALSE, fig.cap = "Plots of reverse read error rates for each possible transition. Points are observed rates for each consensus quality score. The black line shows the estimate error rates from the machine-learning algorithm, while the red line shows the error rates based on Q-scores. There is a good fit between black lines and observed points."}
plotErrors(soil.reverse.error.rate, nominalQ = TRUE)
```


\newpage
## Sample Inference with DADA2

\vspace{10pt}

```{r Roots Sample Inference: Forward Reads, echo = TRUE}
## Run the DADA algorithm on the forward reads with the learned error rate
soil.forward.DADA <- dada(
  derep = soil.filtered.forward.reads,
  err = soil.forward.error.rate,
  multithread = TRUE
)

## Inspect the forward DADA object
soil.forward.DADA[[1]]
# 1487 sequence variants were inferred from 38190 input unique sequences (UPDATE)
```

\vspace{10pt}

```{r Roots Sample Inference: Reverse Reads, echo = TRUE}
## Run the DADA algorithm on the reverse reads with the learned error rate
soil.reverse.DADA <- dada(
  derep = soil.filtered.reverse.reads,
  err = soil.reverse.error.rate,
  multithread = TRUE
)

## Inspect the reverse DADA object
soil.reverse.DADA[[1]]
# 1192 sequence variants were inferred from 48516 input unique sequences (UPDATE)
```


\newpage
## Merge Paired Reads

\vspace{10pt}

```{r Soil: Merge Paired Reads, echo = TRUE}
## Merge forward and reverse reads to obtain the full, denoised sequences
soil.merged.sequences <- mergePairs(
  dadaF = soil.forward.DADA,
  derepF = soil.filtered.forward.reads,
  dadaR = soil.reverse.DADA,
  derepR = soil.filtered.reverse.reads,
  verbose = TRUE
)
```

\vspace{10pt}

## Construct Sequence Table

\vspace{10pt}

```{r Soil: Construct Sequence Table from Merged Paired Reads, echo = TRUE}
## Create an Amplicon Sequence Variant (ASV) table from merged paired reads
soil.sequence.table <- makeSequenceTable(soil.merged.sequences)
```

\vspace{10pt}

## Remove Chimeras

\vspace{10pt}

```{r Soil: Remove Chimeras from the ASV Table, echo = TRUE, results = "hide"}
## Identify chimeric sequences using standard DADA2 parameters
soil.sequence.table.filtered.for.chimeras <- removeBimeraDenovo(
  unqs = soil.sequence.table,
  method = "consensus",
  multithread = TRUE,
  verbose = TRUE
)

## Relative frequency of chimeras
sum(soil.sequence.table.filtered.for.chimeras / sum(soil.sequence.table))
# Chimeras account for approximately 1.09% of all sequences (UPDATE)
```


\newpage
## Track Reads through the DADA2 Pipeline

\vspace{10pt}

```{r Soil: Track Reads, echo = TRUE}
## Function to get unique reads
get_N_uniques <- function(x) {
  sum(getUniques(x))
}

## Determine the number of reads at each step
soil.read.tracking <- tibble(
  soil.read.filtering,
  sapply(soil.forward.DADA, get_N_uniques),
  sapply(soil.reverse.DADA, get_N_uniques),
  sapply(soil.merged.sequences, get_N_uniques),
  rowSums(soil.sequence.table.filtered.for.chimeras)
)

## Set column names
colnames(soil.read.tracking) <- c(
  "Filtered", "Forward_Denoised", "Reverse_Denoised",
  "Merged_Sequences", "ASVs_No_Chimeras"
)

## Set row names
rownames(soil.read.tracking) <- soil.sample.names
```

\vspace{10pt}

```{r Soil: Table of Tracked Sequences, echo = FALSE}
kable(
  soil.read.tracking,
  booktabs = TRUE,
  digits = 3,
  caption = "Number of reads for each step through the bioinformatic pipeline for all soil samples."
) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"))
```










\newpage
# Taxonomy Assignment

## Root

\vspace{10pt}

```{r Roots: Assign Taxonomy Using the RDP Classifier, echo = TRUE}
## Assign taxonomy using the RDP naive Bayesian classifier
root.ASV.RDP.taxonomy.assignment <- assignTaxonomy(
  seqs = root.sequence.table.filtered.for.chimeras,
  refFasta = "rdp_train_set_18.fa.gz",
  tryRC = TRUE,
  taxLevels = c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus"),
  multithread = TRUE
)
```

\vspace{10pt}

## Soil 

```{r Soil: Assign Taxonomy Using the RDP Classifier, echo = TRUE}
## Assign taxonomy using the RDP naive Bayesian classifier
soil.ASV.RDP.taxonomy.assignment <- assignTaxonomy(
  seqs = soil.sequence.table.filtered.for.chimeras,
  refFasta = "rdp_train_set_18.fa.gz",
  tryRC = TRUE,
  taxLevels = c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus"),
  multithread = TRUE
)
```










\newpage
# Export ASV & Taxonomy Assignment Data

\vspace{10pt}

```{r Export ASV & Taxonomy Assignment Data, echo = TRUE}
## ASV abundance matrix
# Root
write_rds(
  root.sequence.table.filtered.for.chimeras,
  file = "data_analysis/2-DADA2_pipeline/root_ASV_abundance_table.rds"
)
# Soil
write_rds(
  soil.sequence.table.filtered.for.chimeras,
  file = "data_analysis/2-DADA2_pipeline/soil_ASV_abundance_table.rds"
)

## ASV taxonomy table
# Root
write_rds(
  root.ASV.RDP.taxonomy.assignment,
  file = "data_analysis/2-DADA2_pipeline/root_ASV_taxonomy_table.rds"
)
# Soil
write_rds(
  soil.ASV.RDP.taxonomy.assignment,
  file = "data_analysis/2-DADA2_pipeline/soil_ASV_taxonomy_table.rds"
)
```










\newpage
# Export Sequences for Phylogenetic Tree

\vspace{10pt}

## Roots

\vspace{10pt}

```{r Roots: Sequences for Phylogenetic Tree, echo = TRUE}
## Compile root sequences
root.sequences <- getSequences(root.sequence.table)
root.sequence.names <- root.sequences

## Export root sequence fasta
seqinr::write.fasta(
	as.list(root.sequences),
	names = root.sequence.names,
	file.out = "root_phylogenetic_tree/root.sequence.table.fasta"
)
```

\vspace{10pt}

## Soil

\vspace{10pt}

```{r Soil: Sequences for Phylogenetic Tree, echo = TRUE}
## Compile soil sequences
soil.sequences <- getSequences(soil.sequence.table)
soil.sequence.names <- soil.sequences

## Export soil sequence fasta
seqinr::write.fasta(
	as.list(soil.sequences),
	names = soil.sequence.names,
	file.out = "soil_phylogenetic_tree/soil_sequence_table.fasta"
)
```

\vspace{10pt}

## Combine Root & Soil Sequences

\vspace{10pt}

```{r Root & Soil Sequences for Phylogenetic Tree, echo = TRUE}
## Merge root and soil sequences
merged.sequences <- mergeSequenceTables(
	root.sequence.table, soil.sequence.table
)

## Compile microbiome sequences
microbiome.sequences <- getSequences(merged.sequences)
microbiome.sequence.names <- microbiome.sequences

## Export soil sequence fasta
seqinr::write.fasta(
	as.list(microbiome.sequences),
	names = microbiome.sequence.names,
	file.out = "microbiome_phylogenetic_tree/microbiome_sequence_table.fasta"
)
```










\newpage
# Save the Workspace

\vspace{10pt}

```{r Save Workspace, include = FALSE}
## Working data
save.image("data_analysis/2-DADA2_pipeline/DADA2_pipeline-full_workspace.Rdata")
```

\vspace{10pt}

# R Session Information

```{r R Packages, echo = FALSE}
df_session_packages <- devtools::session_info()$packages %>%
  as.data.frame(.) %>%
  filter(attached == TRUE) %>%
  dplyr::select(loadedversion, date) %>%
  rownames_to_column()

colnames(df_session_packages) <- c("Package", "Loaded Version", "Date")

kable(
  df_session_packages,
  booktabs = TRUE,
  caption = "Packages required for data management and analysis."
) %>%
  kable_styling(
    full_width = FALSE,
    latex_options = c("HOLD_position", "striped")
  )
```
